# üóìÔ∏è Semana 03
## Temas tratados:
- Crecimiento de Funciones y Notaci√≥n Asint√≥tica
- Notaci√≥n Asint√≥tica O (Cota Superior Asint√≥tica)
- Notaci√≥n Asint√≥tica Œ© (Cota Inferior Asint√≥tica)
- Notaci√≥n Asint√≥tica Œò (Cota Ajustada Asint√≥tica)
- An√°lisis del caso promedio
- C√≥digo
### Crecimiento de Funciones y Notaci√≥n Asint√≥tica
Para evaluar la eficiencia de los algoritmos de manera te√≥rica, nos interesa c√≥mo su tiempo de ejecuci√≥n o uso de memoria crece a medida que el tama√±o de la entrada aumenta. Para esto, utilizamos la notaci√≥n asint√≥tica, que nos permite describir el comportamiento l√≠mite de las funciones.

### Notaci√≥n Asint√≥tica O (Cota Superior Asint√≥tica)
La notaci√≥n O (Big-O) proporciona una cota superior asint√≥tica para el tiempo de ejecuci√≥n (o el consumo de recursos) de un algoritmo. Si decimos que el tiempo de ejecuci√≥n de un algoritmo es O(g(n)), significa que, para entradas lo suficientemente grandes, el tiempo de ejecuci√≥n nunca superar√° un m√∫ltiplo constante de g(n). En t√©rminos formales, una funci√≥n f(n) pertenece a O(g(n)) si existen constantes positivas c y n 0 tales que 0‚â§f(n)‚â§c‚ãÖg(n) para todo n‚â•n 0.
Ejemplo: Si un algoritmo tiene un tiempo de ejecuci√≥n T(n)=3n 
2+2n+5, diremos que T(n)‚ààO(n 2), porque para n lo suficientemente grande, 3n 2+2n+5 no crecer√° m√°s r√°pido que un m√∫ltiplo de n 2.

### Notaci√≥n Asint√≥tica Œ© (Cota Inferior Asint√≥tica)
La notaci√≥n Œ© (Big-Omega) proporciona una cota inferior asint√≥tica. Si el tiempo de ejecuci√≥n de un algoritmo es Œ©(g(n)), significa que, para entradas lo suficientemente grandes, el tiempo de ejecuci√≥n siempre ser√° al menos un m√∫ltiplo constante de g(n). Formalmente, f(n)‚ààŒ©(g(n)) si existen constantes positivas c y n 0 tales que 0‚â§c‚ãÖg(n)‚â§f(n) para todo n‚â•n 0.

-Ejemplo: Para el mismo algoritmo con T(n)=3n 2+2n+5, tambi√©n podr√≠amos decir que T(n)‚ààŒ©(n 2), ya que su tiempo de ejecuci√≥n no ser√° menor que un m√∫ltiplo de n 2.

### Notaci√≥n Asint√≥tica Œò (Cota Ajustada Asint√≥tica)
La notaci√≥n Œò (Theta) proporciona una cota ajustada asint√≥tica. Si el tiempo de ejecuci√≥n de un algoritmo es Œò(g(n)), significa que su tiempo de ejecuci√≥n est√° acotado tanto superior como inferiormente por m√∫ltiplos constantes de g(n). En otras palabras, f(n) est√° en Œò(g(n)) si f(n)‚ààO(g(n)) y f(n)‚ààŒ©(g(n)). Formalmente, existen constantes positivas c 1 ,c 2 y n 0 tales que 0 ‚â§c 1 ‚ãÖg(n)‚â§f(n) ‚â§ c 2 ‚ãÖg(n) para todo n‚â•n 0.
Ejemplo: Un algoritmo con T(n)=3n 2+2n+5 tiene un tiempo de ejecuci√≥n de Œò(n 2), porque n 2 describe de forma precisa su tasa de crecimiento tanto por arriba como por abajo.

### An√°lisis del Caso Promedio
El an√°lisis del caso promedio busca determinar el tiempo de ejecuci√≥n esperado de un algoritmo, considerando la distribuci√≥n probabil√≠stica de todas las posibles entradas. Este tipo de an√°lisis puede ser m√°s complejo que el an√°lisis del caso peor, ya que requiere hacer suposiciones sobre la probabilidad de ocurrencia de cada tipo de entrada. Aunque proporciona una visi√≥n m√°s realista del rendimiento t√≠pico de un algoritmo, sus resultados dependen fuertemente de la validez de estas suposiciones. A menudo, el an√°lisis del caso promedio es m√°s dif√≠cil de realizar matem√°ticamente.

### C√≥digo


